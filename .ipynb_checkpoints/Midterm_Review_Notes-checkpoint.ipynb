{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "midterm review 10/23/2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-10-23 16:09:55--  https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nyc_pluto_16v2%20.zip\n",
      "Resolving www1.nyc.gov... 23.66.229.194, 2600:1400:a:18f::1500, 2600:1400:a:1a3::1500\n",
      "Connecting to www1.nyc.gov|23.66.229.194|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50630337 (48M) [application/zip]\n",
      "Saving to: “nyc_pluto_16v2 .zip”\n",
      "\n",
      "100%[======================================>] 50,630,337  46.5M/s   in 1.0s    \n",
      "\n",
      "2017-10-23 16:09:56 (46.5 MB/s) - “nyc_pluto_16v2 .zip” saved [50630337/50630337]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#reading in file from github. note that you must use the link to the raw data!\n",
    "#tells all the info she needs to reproduce\n",
    "# furl = 'https://raw.githubusercontent.com/...'\n",
    "# guns = pd.read_csv(furl)\n",
    "\n",
    "# if this was not a CSV file, or if I was not using pandas and couldn't read from CSV without downloading,\n",
    "# we have to have the file locally. In that case, we can download the file using bash commands.\n",
    "# URL = 'https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nyc_pluto_16v2%20.zip'\n",
    "!wget https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nyc_pluto_16v2%20.zip # requires that you have a link that you want to wget\n",
    "\n",
    "# PLUTO data example >> copy link address, gives you URL, which you can then wget\n",
    "# https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nyc_pluto_16v2%20.zip\n",
    "\n",
    "# you can test that you have the file with !ls\n",
    "# don't keep code and data in the same repo though:\n",
    "# so we want to move that file\n",
    "# we move it to PUIdata, which we all have\n",
    "# os.getenv(\"PUIDATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cusp/cm4698/PUIdata'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"PUIDATA\")\n",
    "# if you have troubles and don't have PUIDATA\n",
    "# make sure that compute has your PUIDATA directory working and that you can move stuff there\n",
    "# remember how to do it?\n",
    "# os.system(\"mv %s %s\"%(\"nyc_pluto_16v2\\ .zip\", os.getenv(\"PUIDATA\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  nyc_pluto_16v2 .zip\n",
      "  inflating: /home/cusp/cm4698/PUIdata/BORO_zip_files_csv/BK.csv  \n",
      "  inflating: /home/cusp/cm4698/PUIdata/BORO_zip_files_csv/BX.csv  \n",
      "  inflating: /home/cusp/cm4698/PUIdata/BORO_zip_files_csv/MN.csv  \n",
      "  inflating: /home/cusp/cm4698/PUIdata/BORO_zip_files_csv/PLUTODD16v2.pdf  \n",
      "  inflating: /home/cusp/cm4698/PUIdata/BORO_zip_files_csv/Plutolay16v2.pdf  \n",
      "  inflating: /home/cusp/cm4698/PUIdata/BORO_zip_files_csv/PlutoReadme16v2.pdf  \n",
      "  inflating: /home/cusp/cm4698/PUIdata/BORO_zip_files_csv/QN.csv  \n",
      "  inflating: /home/cusp/cm4698/PUIdata/BORO_zip_files_csv/SI.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip -d $PUIDATA nyc_pluto_16v2\\ .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201501-citibike-tripdata.csv\r\n",
      "201501-citibike-tripdata.zip\r\n",
      "201503-citibike-tripdata.csv\r\n",
      "201503-citibike-tripdata.zip\r\n",
      "201507-citibike-tripdata.csv\r\n",
      "201507-citibike-tripdata.zip\r\n",
      "API_NY.GDP.MKTP.CD_DS2_en_csv_v2.csv\r\n",
      "API_SP.POP.TOTL_DS2_en_csv_v2.csv\r\n",
      "BORO_zip_files_csv\r\n",
      "data-pvLFI.csv\r\n",
      "World firearms murders and ownership - Sheet 1.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls $PUIDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if the data is coming from an API\n",
    "# world bank data example\n",
    "\n",
    "from pandas_datareader import wb\n",
    "\n",
    "wb.search('gdp.*US*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example where link is a downloader (similar to an API)\n",
    "# a reasonable thing to do in this case if you don't want to download live is\n",
    "# something along the lines of this:\n",
    "# \"the link in the page I pointed you to is a link to a downlaoder. There are APIs that allow you to interact with the downloader,\n",
    "# but it gets too complicated, so here's the data source in detail, access date and time, and any differences since last time notebook was run.\n",
    "# link, date, and reasons why you couldn't make it reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# she'll want us to integrate sources and combine them\n",
    "# very smart to use pandas in these cases\n",
    "# usually you're merging on a key, need identifiers, etc. pandas is good at this stuff\n",
    "\n",
    "# in the mass shootings example, she's downloaded 4 datasets\n",
    "# they all look a little different\n",
    "# if the names for columns are ridiculous, change them:\n",
    "df.rename(columns = {u'OldName' : 'NewName'}, inplace=True)\n",
    "\n",
    "# if we only want certain columns\n",
    "df[['Country', 'Number of mass shootings']] # in memory, we still have all of the other columns\n",
    "# can overwrite df with another variable name and overwrite the memory\n",
    "\n",
    "# drop if a function of the dataframe\n",
    "# takes labels, axis, inplace # axis is important, because in most cases what we want to drop \n",
    "# drop will take labels you want to drop as an array of labels\n",
    "df = df.drop('Guns/100 inhabitants', axis = 1, inplace = True) # if you don't set it to df, it won't store the drop actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to merge datasets by country\n",
    "# if it's a common name, it will automatically merge on that common column\n",
    "# another option is to tell it actually what to merge on\n",
    "guns.merge(df, right_on=\"Country/Territory\", left_on='Country')\n",
    "\n",
    "# keep in mind that merge might function differently depending on what you want to do\n",
    "# do you want only rows in both datasets, or keep columns that only appear in one?\n",
    "# default will only keep rows that appear in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you end up with an empty df:\n",
    "# keep in mind that the merge is default inner\n",
    "# issue might be datatypes! if you have a integer and a string, or an int32 and int64\n",
    "# first thing to check is whether the column you're merging on is actually the same type\n",
    "# how to change types?:\n",
    "df['Number of mass shootings'].astype(float) # converts the column to a float\n",
    "# have to save it into a variable to make it permanent though\n",
    "df['NumMassShoot'] = df['Number of mass shootings'].astype(float)\n",
    "# always work towards simplication, so convert floating points into integers (happens with zips sometimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# might end up with some missing values after you merge\n",
    "# after merging WB data on pop and gdp, and mass shootings by country and firearms by country, she ended up with a DF\n",
    "# that had mysteriously dropped 3 rows\n",
    "df[-df['Country'].isin(df_['Country'])]\n",
    "# tricky to change values, so be familiar with this:\n",
    "ms.set_value\n",
    "# we can set the second row in the Country column to Belgium\n",
    "ms = ms.set_value(2, 'Country', 'Belgium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you may want to drop one value for a row but not the whole row\n",
    "# you can use the above then to set a certain value to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9df658ebde42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# before you run it, make sure you don't have any columns that only contain NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# to drop NaN values:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# good idea to make a scatterplot in the beginning to understand your data\n",
    "# scatter matrix \n",
    "# before you run it, make sure you don't have any columns that only contain NaN\n",
    "# to drop NaN values:\n",
    "df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting and writing captions\n",
    "# she's going to give us a notebook with package mpld3 which is a novelty and fun to play with\n",
    "# the way a plot in python works:\n",
    "# there is a container for the plots, called the figure\n",
    "fig, ax = plt.suplots()\n",
    "# the plots themselves are subplots, and you can create them in a single line \n",
    "# the axis object is the actual plot\n",
    "# when you add a subplot\n",
    "fig = pl.figure(figsize(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# pl.plot(x,y,'.') is much faster than .scatter\n",
    "# remember axis labels, legends when appropriate\n",
    "# if you don't have legend AND don't describe your data in a caption, you're SOL\n",
    "# always a caption! legend is optional but sometimes useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# captions typically start with a Figure # (helpful for cross referencing)\n",
    "# type of plot, how error bars were generated, obvious outliers (with high y and high x, for example)\n",
    "# she will read the intro, which is the problem setup provided, and the captions to see if it tells the right story\n",
    "# if you want to plot confidence regions, you can plot them\n",
    "# influence plots are important! once you make your fit, tells you what your fit means\n",
    "# generally be weary of points far from zero and big data points, and discuss!\n",
    "# DISCUSS, DISCUSS, DISCUSS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one thing that drives her crazy is when you make a fit to a quadratic function and then just plot it as a back&forth line\n",
    "# this happens if your points are sorted in the right order\n",
    "# you have a number of options to deal with this:\n",
    "# extract coefficients and write your own function (based on linspace that goes from x min to x max)\n",
    "# # if you df is small, easiest way is to create a new df that is a sorted version of your df\n",
    "df1 = dfline.sort_values(by='x')\n",
    "ax.plot(df1.x, model2.predict(df1), color='DarkOrange')\n",
    "\n",
    "# can also just create a DataFrame\n",
    "df1_ = pd.DataFrame({'x':np.linspace(dfline.x.min(), dfline.x.max(), 100)})\n",
    "df1_['x2'] = df1_.x**2\n",
    "# you can only visual things in 2D when they are 2-dimensional\n",
    "# trivial choices that you have to represent that third variable is point color\n",
    "df1_.plot(x='x', y='y', '.', color=df1_.x2, cmap='viridis')\n",
    "# and point size\n",
    "df1_.plot(x='x', y='y', '.', s=df1_.x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# good practice to show beginning of the data and contents of the data\n",
    "guns.columns\n",
    "guns.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
