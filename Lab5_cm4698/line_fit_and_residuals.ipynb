{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "import os\n",
    "import json\n",
    "s = json.load( open(os.getenv('PUI2016')+\"/fbb_matplotlibrc.json\") )\n",
    "pl.rcParams.update(s)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "np.random.seed(99)\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##this function will fit a line woth statsmodels packages, \n",
    "##both with and without including the noise int he fir parameter (WLS and OLS respectively)\n",
    "##also i can use the statsmodels.formula package passing it a formula, which i will need\n",
    "##when i want to fit a curve, not a straight line, to the data\n",
    "def myregression(x, y, method=None): \n",
    "    if method == None or method == 'O':\n",
    "        rm = sm.OLS(y, x)\n",
    "    elif method == 'W':\n",
    "        rm = sm.WLS(y, x)\n",
    "    else:\n",
    "        print (\"Problem in the way you called myregression\")\n",
    "        return -1\n",
    "            \n",
    "    reg = rm.fit()\n",
    "    print (\"linear regression slope {}\".format(reg.summary()))\n",
    "    return reg\n",
    "\n",
    "def line(a, b, x):\n",
    "    return a*x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating simulated data: just a line \n",
    "## then i fit it with a line fit (linear first degree fit) and plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(10,100,100)\n",
    "y = line(0.7, 0, x)\n",
    "\n",
    "mrnew = myregression(x, y)\n",
    "xnew = np.linspace(10,100,10)\n",
    "fig = pl.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(221)\n",
    "ax.scatter(x, y, label = \"just a line\")\n",
    "ax.set_xlabel('independent variable')\n",
    "ax.set_ylabel('dependent variable')\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax2.scatter(x, y, label = \"just a line\")\n",
    "ax2.set_xlabel('independent variable')\n",
    "ax2.set_ylabel('dependent variable')\n",
    "ax2.plot(xnew, mrnew.predict(xnew), 'r', alpha=0.5, \n",
    "         label = \"statsmodels fit\")\n",
    "ax2.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding noise to the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = y + np.random.randn(100) * 2.5\n",
    "mrold = mrnew\n",
    "\n",
    "#I use just OLD: the ordinary square fit which does not take the error bars \n",
    "#into account\n",
    "#refer to statsmodels documentation!!\n",
    "mrnew = myregression(x, y)\n",
    "\n",
    "fig = pl.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(221)\n",
    "ax.scatter(x, y, label = \"plus some noise\")\n",
    "ax.plot(xnew, mrold.predict(xnew), 'k', alpha=0.5, label='old fit')\n",
    "\n",
    "ax.set_xlabel('independent variable')\n",
    "ax.set_ylabel('dependent variable')\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "ax.scatter(x, y, label = \"plus some noise\")\n",
    "ax.plot(xnew, mrnew.predict(xnew), 'r', alpha=0.5, label='new fit')\n",
    "\n",
    "ax.set_xlabel('independent variable')\n",
    "ax.set_ylabel('dependent variable')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding a bit of curvature to my line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y = y+np.cos(x/100*2*np.pi*10.0)\n",
    "y = y + 3e-3 * ((x - 50)**2)\n",
    "mrolder = mrold\n",
    "mrold = mrnew\n",
    "\n",
    "#now i fit the data taking into account the errorbars: \n",
    "#u ise WLS (weighted square fit) \n",
    "#instead of OLS (ordinary square fit)\n",
    "mrnew = myregression(x, y, method='W')\n",
    "\n",
    "fig = pl.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(221)\n",
    "e = np.random.rand(100)*2.5+2.5\n",
    "ax.errorbar(x, y, yerr=e, fmt='.', label = \"and some structure\")\n",
    "ax.plot(xnew, mrolder.predict(xnew), 'k', alpha=0.4,\n",
    "       label = \"fit to line only\")\n",
    "ax.plot(xnew, mrold.predict(xnew), 'k', alpha=0.7,\n",
    "       label = \"fit to line and noise\")\n",
    "\n",
    "ax.set_xlabel('independent variable')\n",
    "ax.set_ylabel('dependent variable')\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "ax.errorbar(x, y, yerr=e, fmt='.', label = \"and some structure\")\n",
    "ax.plot(xnew, mrold.predict(xnew), 'k', alpha=0.7,      \n",
    "       label = \"fit to line and noise\")\n",
    "\n",
    "ax.plot(xnew, mrnew.predict(xnew), 'r', alpha=0.5,\n",
    "       label = \"fit to noisy curve\")\n",
    "\n",
    "ax.set_xlabel('independent variable')\n",
    "ax.set_ylabel('dependent variable')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to fit a curve i can use statsmodels formula, or i can use scipy polyfit. \n",
    "#here i take the residuals from the previous line regression, \n",
    "#which are a curve, and i fir those with a second degree polynomial\n",
    "\n",
    "#here is an example of how to do it with scipy.polyfit  \n",
    "#(the number 2 refers to the degree of the polynomial i want to fit : \n",
    "#refer to the scipy documentation!)\n",
    "\n",
    "mrres = np.polyfit(x, y-mrnew.predict(x), 2)\n",
    "#these are the parameters of the fit: the a b and c in \n",
    "#ax^2 + bx + c\n",
    "print ('numpy polyfit parameters', mrres)\n",
    "fig = pl.figure(figsize=(10,10))\n",
    "ax=fig.add_subplot(221)\n",
    "ax.plot(x, y-mrnew.predict(x), 'o', color='DarkGreen', label='residuals')\n",
    "ax.plot(x, y-mrnew.predict(x), 'k-')\n",
    "\n",
    "ax.plot(x, mrres[0] * x**2 + mrres[1] * x + mrres[2], 'y',\n",
    "       label = 'fit to the residuals (with numpy)')\n",
    "ax.set_xlabel('independent variable')\n",
    "ax.set_ylabel('dependent variable')\n",
    "ax.legend()\n",
    "\n",
    "ax=fig.add_subplot(222)\n",
    "\n",
    "#and i plot the \"residual of the residuals\".... just for fun. \n",
    "#this is not normally something which one would include in the analysis\n",
    "ax.plot(x,y - mrnew.predict(x) - (mrres[0] * x**2 + \n",
    "                                  mrres[1] * x + \n",
    "                                  mrres[2]), 'y',\n",
    "       label = \"rectified residuals\")\n",
    "ax.plot([x.min(), x.max()], [0,0],  '-', color='IndianRed',\n",
    "       label = \"no residuals\")\n",
    "\n",
    "print ('mean of residuals {0:.2f} ({0:.2e})'.format(\n",
    "                mean(y - mrnew.predict(x) - (mrres[1] +  mrres[0] * (x)))))\n",
    "print ('sum squared of residuals {0:.2f} ({0:.2e})'.format(\n",
    "        np.sqrt(sum((y - mrnew.predict(x))**2))))\n",
    "ax.set_xlabel('independent variable')\n",
    "ax.set_ylabel('dependent variable')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# of course i could have fit a curve to my data in the first place: i did not need to do a line fit, and then fit a curve to the residuals. that may cme in handy if the residuals have a lot of complex structure: for example if i think they may be periodic and i may want to fit a sine wave to it, but generally if i see a set of data which is curvy iw ill fit a curve to it: \n",
    "\n",
    "## lets fit a second degree polynomial to the data i had created with y = y+3e-3 ((x-50)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##second degree polynomial: arguments are i\n",
    "#independent variable, dependent variable, degree of the polynomial\n",
    "mrnew = np.polyfit(x, y, 2)\n",
    "\n",
    "pl.plot(x, y, 'o', color='DarkGreen', label='all in one: ' + \n",
    "        'line+noise+curvature')\n",
    "pl.plot(x, y, 'k-')\n",
    "\n",
    "\n",
    "pl.plot(xnew, np.poly1d(mrnew)(xnew), 'y', alpha=1, \n",
    "        label = '2D polynomial fit with numpy.polyfit')\n",
    "\n",
    "pl.xlabel('independent variable')\n",
    "pl.ylabel('dependent variable')\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with statsmodels that is:\n",
    "smreg = smf.ols(formula=\"y ~ x1 + I((x1)) + I((x1)**2)\", \n",
    "                data={\"x1\" : x, \"y\" : y} ).fit()\n",
    "print (smreg.summary())\n",
    "pl.plot(x, y, 'o', color='DarkGreen', label='all in one : ' + \n",
    "        'line+noise+curvature')\n",
    "pl.plot(x, y, 'k-')\n",
    "\n",
    "\n",
    "pl.plot(xnew, smreg.predict(exog=dict(x1=xnew)), \n",
    "        label = '2D polynomial fit with statsmodels.ols')\n",
    "pl.xlabel('independent variable')\n",
    "pl.ylabel('dependent variable')\n",
    "pl.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mrold = mrnew\n",
    "mrnew = np.polyfit(x, y, 2)\n",
    "pl.plot([x.min(), x.max()], [0,0],  '-', color='IndianRed')\n",
    "\n",
    "e = np.random.rand(100)*2.5+2.5\n",
    "#pl.errorbar(x, y, yerr=e, label = \"and some structure\")\n",
    "pl.plot(x, y - np.poly1d(mrnew)(x), 'ro', alpha=0.5,\n",
    "       label = 'residuals from pylab model fit')\n",
    "pl.plot(x, y - np.poly1d(mrnew)(x), 'k', alpha=0.5)\n",
    "\n",
    "\n",
    "pl.xlabel('independent variable')\n",
    "pl.ylabel('dependent variable')\n",
    "pl.legend()\n",
    "print ('mean of residuals {0:.2f} ({0:.2e})'.format(mean(y - \n",
    "                                                       (mrnew[2] + \n",
    "                                                       mrnew[1] * (x) + \n",
    "                                                       mrnew[0] * (x**2)\n",
    "                                                       ))))\n",
    "print ('sum squared of residuals {0:.2f} ({0:.2e})'.format(np.sqrt(sum((y - \n",
    "                                                      (mrnew[2] + \n",
    "                                                       mrnew[1] * \n",
    "                         (x) + mrnew[0] * (x**2)))))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# many more regression diagnostics!\n",
    "http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/regression_diagnostics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 10/19 in-class:\n",
    "Fit both a line y=ax+b to it and a quadratic equation y=ax^2 + bx +c to it with statsmodels.formula.api package. Can you compare these models w LE test? Try write down the LR statistics and compare it to a chi sq table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # to generate random numbers\n",
    "import statsmodels as st\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.27911549,  42.19234063,  38.66526982,  32.05184381,\n",
       "        49.54925809,  54.72935004,  18.64145099,  47.12595182,\n",
       "        18.65470167,  40.24042369])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some points\n",
    "def line(a, b, x):\n",
    "    # add Gaussian error\n",
    "    # make a vector of those that is as long as x\n",
    "    yerr = np.random.randn(len(x))\n",
    "    # multiply by something comparable to the square root of y\n",
    "    yerr = yerr * (np.sqrt(a * x + b).mean())\n",
    "    \"\"\"pass x-axis to the line\"\"\"\n",
    "    return a * x + b + yerr\n",
    "\n",
    "x = np.random.rand(10) * 10 # generates 10 numbers between 0 and 10 (was 1)\n",
    "line(5, 7, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7aefa62c88>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n62N/mSoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7aefaa9e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot that\n",
    "\n",
    "line1 = line(5, 7, x)\n",
    "\n",
    "pl.plot(x, line1, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/anaconda/root/envs/PUI2016_Python3/lib/python3.5/site-packages/scipy/stats/stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   71.37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Oct 2017</td> <th>  Prob (F-statistic):</th> <td>2.94e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:18:30</td>     <th>  Log-Likelihood:    </th> <td> -31.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    10</td>      <th>  AIC:               </th> <td>   66.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   66.75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    6.0414</td> <td>    3.890</td> <td>    1.553</td> <td> 0.159</td> <td>   -2.928    15.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    5.1506</td> <td>    0.610</td> <td>    8.448</td> <td> 0.000</td> <td>    3.745     6.557</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.388</td> <th>  Durbin-Watson:     </th> <td>   1.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.500</td> <th>  Jarque-Bera (JB):  </th> <td>   0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.011</td> <th>  Prob(JB):          </th> <td>   0.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.308</td> <th>  Cond. No.          </th> <td>    13.2</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.899\n",
       "Model:                            OLS   Adj. R-squared:                  0.887\n",
       "Method:                 Least Squares   F-statistic:                     71.37\n",
       "Date:                Thu, 19 Oct 2017   Prob (F-statistic):           2.94e-05\n",
       "Time:                        11:18:30   Log-Likelihood:                -31.074\n",
       "No. Observations:                  10   AIC:                             66.15\n",
       "Df Residuals:                       8   BIC:                             66.75\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      6.0414      3.890      1.553      0.159        -2.928    15.011\n",
       "x              5.1506      0.610      8.448      0.000         3.745     6.557\n",
       "==============================================================================\n",
       "Omnibus:                        1.388   Durbin-Watson:                   1.596\n",
       "Prob(Omnibus):                  0.500   Jarque-Bera (JB):                0.040\n",
       "Skew:                           0.011   Prob(JB):                        0.980\n",
       "Kurtosis:                       3.308   Cond. No.                         13.2\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n62N/mSoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7aefaa7f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit a line to that with stats models\n",
    "# use formula inside of statsmodels\n",
    "\n",
    "# let's create a data frame\n",
    "# good way to convert any array to a dataframe\n",
    "# you can also create an empty df and add variables to it\n",
    "dfline = pd.DataFrame({'x': x,'y': line1})\n",
    "# call OLS, lowercase\n",
    "# smf.ols? >> look at the parameters\n",
    "fittedline = smf.ols(formula='y ~ x', data = dfline) # twiddle means y is proportional to x # our formula is still y = ax+b\n",
    "model = fittedline.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fittedline2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3d334b6793d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfittedlin2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y ~ I(x**2)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfittedline2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# should see R^2 improve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# not suprisingly, we increased the # of parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fittedline2' is not defined"
     ]
    }
   ],
   "source": [
    "fittedlin2 = smf.ols(formula='y ~ I(x**2)', data = dfline)\n",
    "model2 = fittedline2.fit()\n",
    "model2.summary()\n",
    "# should see R^2 improve\n",
    "# not suprisingly, we increased the # of parameters\n",
    "# adjusted-rsquared had actually decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OLSResults.compare_lr_test(restricted) # pass your more complex model to compare with your basic model\n",
    "# will give you chi-square tests, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11.992187999999999px",
    "width": "1.992188px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
